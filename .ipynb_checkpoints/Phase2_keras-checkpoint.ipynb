{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from anhCustom_lossFunction.ipynb\n",
      "[ 0.  2.  4.  6.  8. 10. 12. 14. 16. 18. 20. 22. 24. 26. 28. 30. 32. 34.\n",
      " 36. 38. 40. 42. 44. 46. 48. 50. 52. 54. 56. 58. 60. 62. 64. 66. 68. 70.\n",
      " 72. 74. 76. 78. 80. 82. 84. 86. 88. 90. 92. 94. 96. 98.]\n",
      "4900\n",
      "-794.5668964088594\n",
      "-890.7847980596202\n"
     ]
    },
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<string>, line 6)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"c:\\users\\saad.naeem\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3418\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"<ipython-input-1-e96bcc871ad8>\"\u001b[0m, line \u001b[0;32m2\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    from anhCustom_lossFunction import *\n",
      "  File \u001b[0;32m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[0;32m991\u001b[0m, in \u001b[0;35m_find_and_load\u001b[0m\n",
      "  File \u001b[0;32m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[0;32m975\u001b[0m, in \u001b[0;35m_find_and_load_unlocked\u001b[0m\n",
      "  File \u001b[0;32m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[0;32m655\u001b[0m, in \u001b[0;35m_load_unlocked\u001b[0m\n",
      "  File \u001b[0;32m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[0;32m618\u001b[0m, in \u001b[0;35m_load_backward_compatible\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"c:\\users\\saad.naeem\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\import_ipynb.py\"\u001b[1;36m, line \u001b[1;32m61\u001b[1;36m, in \u001b[1;35mload_module\u001b[1;36m\u001b[0m\n\u001b[1;33m    exec(code, mod.__dict__)\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"<string>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    Ka = tf.tensordot(K_A, y_pred, axes=1)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from anhCustom_lossFunction import *\n",
    "import pandas\n",
    "import tensorflow.keras as keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import Input\n",
    "from keras import Model\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.layers import concatenate\n",
    "import numpy\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras import layers\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to run: \n",
    "1. Specify variables J,z,t,s,t_individual, and their lenghts\n",
    "2. Using that the lenght of the tensorproduct of J and z, put that number of zeros in Y\n",
    "3. Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = np.arange(0.01,0.99,1/1000)\n",
    "J1 = np.arange(0,100,2.0)\n",
    "\n",
    "\n",
    "J1 = J/(J+2)\n",
    "\n",
    "\n",
    "#standard scaling\n",
    "# J1 = J.reshape((len(J1), 1))\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(J1)\n",
    "# J1 = scaler.transform(J1)\n",
    "# print(J1.shape)\n",
    "\n",
    "X = []\n",
    "X = [[j, Z] for j in J for Z in z]\n",
    "\n",
    "#X = [[j, Z] for Z in z1 for j in J1]\n",
    "\n",
    "X = np.array(X)\n",
    "print(X.shape)\n",
    "Y = []\n",
    "for i in range(0,4900, 1):\n",
    "    Y.append(i)\n",
    "    \n",
    "Y = np.array(Y)\n",
    "# Y = np.zeros((X.shape[0],1))\n",
    "print(Y.shape)\n",
    "print(np.kron(J,z).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import datasets, layers, models, Input\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from keras.callbacks import LambdaCallback\n",
    "\n",
    "#Sets initial input shape\n",
    "model = models.Sequential()\n",
    "model.add(Input(shape=(2)))\n",
    "#study activation functions\n",
    "\n",
    "\n",
    "#\n",
    "# W1 = TF.TENSRO([[0.3,0.2,0.1,0.6,0.5],[0.5,0.8,0.2,0.1,0.5]])\n",
    "\n",
    "# W2 = np.array([[0.2, 0.3,0.1],[0.5,0.8,0.2], [0.2,0.1,0.5], [0.2,0.1,0.6], [0.3,0.2,0.1]])\n",
    "\n",
    "# W3=np.array([[0.9, 0.2,0.1]])\n",
    "\n",
    "\n",
    "model.add(layers.Dense(5, activation='relu', kernel_initializer=initializers.RandomNormal(stddev=0.3)))\n",
    "model.add(layers.Dense(3, activation='relu', kernel_initializer=initializers.RandomNormal(stddev=0.1)))\n",
    "model.add(layers.Dense(1, activation='sigmoid', kernel_initializer=initializers.RandomNormal(stddev=0.4))) #make sure its between 0 and 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Callback function\n",
    "print_weights = LambdaCallback(on_epoch_end=lambda batch, logs: print(model.layers[0].get_weights()))\n",
    "\n",
    "#NN learning parameters\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.01,\n",
    "    decay_steps=2000,\n",
    "    decay_rate=0.9)\n",
    "opt = keras.optimizers.Adagrad(learning_rate=lr_schedule)\n",
    "# loss_fn = Custom_Loss_Function()\n",
    "model.compile(optimizer =opt, loss=Custom_Loss_Function, metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_callback = model.fit(X, Y, epochs=50000, batch_size=np.kron(J,z).shape[0], verbose=1 , shuffle = False,  callbacks = [print_weights])\n",
    "loss_history = history_callback.history[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"my_model\")\n",
    "loss_history = np.array(loss_history)\n",
    "A = loss_history[-1]\n",
    "print(A)\n",
    "#A= np.reshape(1,)\n",
    "\n",
    "#np.savetxt(\"Weights/0.1/loss.txt\", [A],fmt='%1.4e')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create array of [sum1, sum2, sum3]\n",
    "[crossing_Symmetry_Square(M, model.predict(X)).numpy(),einstein_Gravity_Min(K_A, model.predict(X),1).numpy(),tf.tensordot(K_B, model.predict(X), axes=1).numpy()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listName=[\"one\",\"two\",\"three\"]\n",
    "print(listName[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test cases\n",
    "print(model.predict(X))\n",
    "a_file = open(\"Weights/0.1/F.txt\", \"w\")\n",
    "#for row in model.predict(X):\n",
    "np.savetxt(a_file, model.predict(X))\n",
    "a_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stable x1 = J=0\n",
    "zz = np.arange(0.01,0.99,1/200)\n",
    "\n",
    "X11 = [[0, Z] for Z in zz]\n",
    "X22 = [[2, Z] for Z in zz]\n",
    "X33 = [[4, Z] for Z in zz]\n",
    "X44 = [[10, Z] for Z in zz]\n",
    "X55 = [[16, Z] for Z in zz]\n",
    "X66 = [[20, Z] for Z in zz]\n",
    "zz = 1/zz\n",
    "\n",
    "\n",
    "plt.plot(zz, model.predict(X11),color = 'r' )\n",
    "plt.plot(zz, model.predict(X22), color = 'b')\n",
    "plt.plot(zz, model.predict(X33),color = 'g')\n",
    "plt.plot(zz, model.predict(X44),color = 'y')\n",
    "plt.plot(zz, model.predict(X55))\n",
    "plt.plot(zz, model.predict(X66))\n",
    "plt.xlabel(\"Energy\")\n",
    "plt.ylabel(\"F\")\n",
    "plt.legend(['Spin-0','Spin-2','Spin-4','Spin-10','Spin-16','Spin-20'])\n",
    "#plt.savefig('Weights/0.1/plt.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
