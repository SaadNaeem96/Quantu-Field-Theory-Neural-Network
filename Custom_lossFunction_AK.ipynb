{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable and Function initiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define variables J, z, s,t\n",
    "J: spin $\\in 2\\mathbb{Z}^+$ <br>\n",
    "z$=1/m^2$ : inverse energy $\\in (0,1)$ <br>\n",
    "s,t: Mandelstam variables $\\in (-1,0)$ subject to the constraint $s+t>-1$ <br>\n",
    "For $K^{\\beta}$, we have $t \\in (-1,0)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of z is (98,), while shape of J is (50,)\n",
      "Shape of s and t is (500,), while shape of t_individual is (500,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from random import seed\n",
    "from random import random\n",
    "import array as arr\n",
    "\n",
    "# J,z\n",
    "z = np.arange(0.01,0.99,1/100)\n",
    "N = len(z)\n",
    "J = np.arange(0,100,2.0)\n",
    "print(\"Shape of z is {}, while shape of J is {}\".format(z.shape,J.shape))\n",
    "\n",
    "# generate random floating point values for s and t\n",
    "# Used for M(s,t)\n",
    "# Set number of s,t\n",
    "length_st=500\n",
    "seed(1)\n",
    "s = arr.array('f')\n",
    "t = arr.array('f')\n",
    "\n",
    "for _ in range(length_st):\n",
    "    # generate random numbers between (-1,0) for s\n",
    "    # Restrict between -(0.1,0.9) to avoid possible boundary singularities\n",
    "    value_s=-np.random.uniform(low=0.1,high=0.9)\n",
    "    s.append(value_s)\n",
    "    \n",
    "    # make t given restriction s+t> -1\n",
    "    # further restrict between -(0.1,0.9) to avoid possible boundary singularities\n",
    "    value_t = np.random.uniform(low=-value_s-0.9, high=0.1)\n",
    "    t.append(value_t)\n",
    "    \n",
    "s = np.array(s)\n",
    "t = np.array(t)\n",
    "\n",
    "#generate random momentum transfers t E (-1,0)\n",
    "# Used for K^\\beta\n",
    "t_individual= -1*np.random.rand(length_st)\n",
    "print(\"Shape of s and t is {}, while shape of t_individual is {}\".format(s.shape,t_individual.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions used in Loss Function\n",
    "The Loss function is defined as\n",
    "$$ L[F] = |K \\cdot F|^2 + \\alpha |K^{\\alpha} \\cdot F - c |^2 - \\beta K^{\\beta} \\cdot F,$$\n",
    "where the index notation discretizes the Mandelstam variables $s_i,t_j$. We refer to the first term as the \"Crossing symmetry constraint\", the second as the \"Einstein Gravity minimisation constraint\" and the last one as the \"Einstein Gravity maximisation\".\n",
    "<br>\n",
    "<br>\n",
    "The individual consistuents of this equation include:\n",
    "$$K(s,t;J,z) = \\frac{2}{\\pi} \\frac{(1+z t)(2+z t)}{(1-z t)(1+z(s+t))s(s+t)} \\tilde{P}_J(1+2zt), $$\n",
    "$$K^{\\alpha}(t;J,z) = -\\frac{2t}{\\pi} z^{\\frac{d}{2}-1} (2+t z) \\tilde{P}_J(1+2zt),$$\n",
    "$$K^{\\beta}(J,z) = \\frac{4}{\\pi} z^{\\frac{d}{2}+1} \\tilde{P}_J(1).$$\n",
    "\n",
    "The function $\\tilde{P}_J(x)$ is defined as\n",
    "$$\\tilde{P}_J(x) = 16\\pi(2J+1)P_J(x), \\qquad d=4,$$\n",
    "where $P_J(x)$ is a Legendre Polynomial.\n",
    "<br> <br>\n",
    "Below, we define $M$ as the 2D array $K_{ij}$ labelling $K(s_i,t_i;J,z)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions defining K's\n",
    "import scipy\n",
    "import scipy.integrate as integrate\n",
    "from scipy.integrate import quad\n",
    "import scipy.special\n",
    "\n",
    "#Calculate M given array of z and J, for specific points (s,t)\n",
    "def Mst_Mts(s,t,z,J):\n",
    "    return (M_withoutF(s,t,z,J) - M_withoutF(t,s,z,J))/N\n",
    "\n",
    "#K_{ij} // M(s,t) matrix\n",
    "def M_withoutF(s,t,z,J):   # use eq 2.6\n",
    "    sum = 0\n",
    "    A= []\n",
    "    B = []\n",
    "    for j in range(len(J)):\n",
    "        for Z in z:\n",
    "            a = 2/math.pi\n",
    "            b = a*Z\n",
    "            c = b*(1+Z*t)*(2+Z*t)\n",
    "            d = c*np.array(P_J(1+2*Z*t, j))\n",
    "            e = (1-Z*t)*(1+Z*(s+t))*s*(s+t)\n",
    "            sum += d/e\n",
    "            B.append(sum)\n",
    "\n",
    "    B= np.array(B)\n",
    "    return B\n",
    "\n",
    "def P_J(x, J):\n",
    "    B = scipy.special.lpmv(0, J, x)\n",
    "    C = 16*math.pi*(2*J +1)\n",
    "    D = C*B\n",
    "    return D\n",
    "\n",
    "def Gamma(z):\n",
    "    return scipy.special.gamma(z)\n",
    "\n",
    "def hypergeometric(a,b,c,d):\n",
    "    return scipy.special.hyp2f1(a,b,c,d)\n",
    "\n",
    "#K^\\alpha vector\n",
    "def K_alpha(t, J, z):\n",
    "    sum = 0\n",
    "    k = []\n",
    "    for j2 in J[0:]:\n",
    "        for z2 in z[0:]:\n",
    "            \n",
    "            A = (-2*t/math.pi)\n",
    "            B = A*z2\n",
    "            C = B*(2 +t*z2)\n",
    "            D = C*(P_J(1+2*z2*t, j2))\n",
    "            sum = D\n",
    "            k.append(sum)\n",
    "            sum = 0\n",
    "    \n",
    "    return k\n",
    "\n",
    "#K^{\\beta} vector\n",
    "def K_Beta(J,z):\n",
    "    sum =0\n",
    "    A = []\n",
    "    for j in J:\n",
    "        for Z in z:\n",
    "            sum += (4/math.pi)*Z**(3)*P_J(1,j)\n",
    "            A.append(sum/N)\n",
    "        \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K initialization block // Set as global variables\n",
    "#Kij\n",
    "M=[]\n",
    "for i in range(len(s)):\n",
    "    M.append(Mst_Mts(s[i],t[i],z,J))   \n",
    "    \n",
    "M= np.array(M)  \n",
    "M =tf.convert_to_tensor(M, tf.float64)\n",
    "\n",
    "#KA\n",
    "K_A = []\n",
    "for t1 in t_individual:\n",
    "    value = K_alpha(t1,J,z)\n",
    "    #should be appending vectors\n",
    "    K_A.append(value)\n",
    "K_A= np.array(K_A)\n",
    "K_A =tf.convert_to_tensor(K_A, tf.float64)\n",
    "\n",
    "#KB\n",
    "K_B = K_Beta(J,z)\n",
    "K_B= np.array(K_B)\n",
    "K_B = np.transpose(K_B)\n",
    "K_B =tf.convert_to_tensor(K_B, tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss function block\n",
    "def crossing_Symmetry_Square(M, y_pred):\n",
    "    Mf = tf.tensordot(M, y_pred, axes=1)\n",
    "    Mf = tf.square(Mf)\n",
    "    return tf.reduce_sum(Mf)\n",
    "\n",
    "def einstein_Gravity_Min(K_A, y_pred, constant):\n",
    "    Ka = tf.tensordot(K_A, y_pred, axes=1)\n",
    "    Ka = Ka - constant\n",
    "    Ka = tf.square(Ka)\n",
    "    return tf.reduce_sum(Ka)\n",
    "\n",
    "def Custom_Loss_Function(y_true, y_pred):   \n",
    "    alpha = 10**2\n",
    "    beta = 10**1\n",
    "\n",
    "    # first term\n",
    "    sum1 = crossing_Symmetry_Square(M, y_pred)\n",
    "   \n",
    "    #second term\n",
    "    sum2 = einstein_Gravity_Min(K_A, y_pred, 1)\n",
    "   \n",
    "    #third term\n",
    "    Kb = tf.tensordot(K_B, y_pred, axes=1)\n",
    "    sum3 = Kb\n",
    "    \n",
    "    # Change sign on sum3 if we want to maximize (-) or minimize (+) wrt EG\n",
    "    return sum1 + alpha*sum2 -beta*sum3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.368432560917732e+24"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F2 = np.ones(4900)\n",
    "F2 = F2/1000\n",
    "F1 = np.random.rand(4900)\n",
    "c  = 1\n",
    "alpha = 10**10\n",
    "beta = 10**20\n",
    "Custom_Loss_Function(F1, F2).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
